{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "## Deadline: Jan 27, 2024\n",
    "\n",
    "### Instructions\n",
    "Submit one Python notebook file for grading. Your file must include mathematical work (type it or insert pictures of your handwritten work), **text expalanations** of your work, **well-commented code**, and the **outputs** from your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ridge regression is a modified version of linear regression that penelizes the coefficients for being large. It accomplishes this by adding a so-called $L^2$ penalty term to the loss function (e.g. mean squared error): $L(\\theta)=\\frac{1}{n}\\sum\\limits_{i=1}^n \\left(\\hat{f}(x_i)-y_i\\right)^2 + \\lambda\\sum\\limits_{i=1}^d \\theta_i^2$\n",
    "\n",
    "    where $\\lambda>0$ is a **hyperparameter** that must be tuned by the user. An appropriate choice of $\\lambda$ can often help with learning datasets where the input features are highly correlated or it can help with an overfitting problem.\n",
    "\n",
    "     a. **[5 points]** Write each part of $L(\\theta)$ in matrix-vector form where $\\hat{f}$ is a LBF expansion regression model. Define each matrix and vector separately by writing their elements with subscripts, and state their dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression = $L(\\theta)=\\frac{1}{n}\\sum\\limits_{i=1}^n \\left(\\hat{f}(x_i)-y_i\\right)^2 + \\lambda\\sum\\limits_{i=1}^d \\theta_i^2$\n",
    "\n",
    "<!-- Loss Function = $\\frac{1}{n}\\sum\\limits_{i=1}^n \\left(\\hat{f}(x_i)-y_i\\right)^2$\n",
    "\n",
    "$L^2$ Penalty Term = $\\lambda\\sum\\limits_{i=1}^d \\theta_i^2$ -->\n",
    "\n",
    "$$X = \\begin{bmatrix}\n",
    "x_1 & ... & x_n\\\\\n",
    "... & ... & ... \\\\\n",
    "x_d & ... & x_{nd}\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$X_h = \\begin{bmatrix}\n",
    "h_0(x_1) & ... & h_M(x_1)\\\\\n",
    "... & ... & ... \\\\\n",
    "h_0(x_c) & ... & h_M(x_{n})\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Firstly, we can pull out our constant $\\frac{1}{n}$. In addtion to this, we know that we can represent $\\hat{f}({x_i})$ in matrix vector form as $\\hat{f}(X) = X_h(\\theta)$. We can also represent the value $y_i$ as $y$.  \n",
    "  \n",
    "Thus, for our Ridge regression function can be represented as, $\\frac{1}{n}||X_h\\theta - y||^2_2$.  \n",
    "  \n",
    "For our penalty term, $\\lambda$ remains, however, to represent $\\lambda\\sum\\limits_{i=1}^d \\theta_i^2$ in matrix vector form we take our $\\theta_i^2$ term and represent it as, $\\theta^T\\theta$ because we are squaring the $\\theta$ value we must multiply it by the transpose of that matrix.  \n",
    "  \n",
    "Finally, we come to our function written in matrix vector form:\n",
    "\n",
    "$L(\\theta) = \\frac{1}{n}||X_h\\theta - y||^2_2 + \\lambda\\theta^T\\theta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **[5 points]** Solve the following optimization problem by hand for the loss function $L$ above $\\min\\limits_{\\theta\\in\\mathbb{R}^{d+1}} L(\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can expend the normalized terms in the above function and represent them as:  \n",
    "  \n",
    "$\\frac{1}{n}(X_h\\theta-y)^T(X_h\\theta-y)$  \n",
    "  \n",
    "At this point, we can pull out our fraction $\\frac{1}{n}$ for the time being because it is a constant. We will extend our transpose to give us:  \n",
    "  \n",
    "$((X_h\\theta)^T-y^T)(X_h\\theta-y)$  \n",
    "  \n",
    "After doing this we can FOIL our function out to give us:  \n",
    "  \n",
    "$(X_h\\theta)^TX_h\\theta - (X_h\\theta)^Ty - y^TX_h\\theta + y^Ty = \\theta^TX_h^TX_h\\theta - 2\\theta^TX_h^Ty + y^Ty$  \n",
    "  \n",
    "Once we have simplified our function we can now start finding the minimum.\n",
    "\n",
    "$L(\\theta) = \\frac{1}{n}(\\theta^TX_h^TX_h\\theta - 2\\theta^TX_h^Ty+y^Ty) + \\lambda\\theta^t\\theta$  \n",
    "\n",
    "$\\nabla(\\theta) = \\frac{1}{n}(2X_h^TX_h\\theta - 2X_h^Ty) + 2\\lambda\\theta$  \n",
    "\n",
    "$0 = \\frac{1}{n}X_h^TX_h\\theta - \\frac{1}{n}X_h^Ty + \\lambda\\theta$  \n",
    "\n",
    "$\\frac{1}{n}X_h^Ty = \\frac{1}{n}X_h^TX_h\\theta + \\lambda\\theta$  \n",
    "\n",
    "$\\frac{1}{n}X_h^Ty = (\\frac{1}{n}X_h^TX_h + \\lambda I)\\theta$  \n",
    "\n",
    "$\\theta = (\\frac{1}{n}X_h^TX_h+\\lambda I)^{-1}\\frac{1}{n}X_h^Ty$\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. **[5 points]** Write a Python class for this ridge LBF expansion regression model with a `fit` function applying the formula from part (b) to compute the parameters $\\theta$ and a `predict` function to make predictions for input data after the model has been fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LBFExpansion:\n",
    "    # fit the model to the data\n",
    "    def fit(self, X, y, λ):\n",
    "        # save the training data\n",
    "        self.data = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # save the training labels\n",
    "        self.outputs = y\n",
    "        \n",
    "        # find the beta values that minimize the sum of squared errors\n",
    "        X = self.data\n",
    "        n = X.shape[1]\n",
    "        I = np.identity(n)\n",
    "\n",
    "        # Ridge Regression function found in the previous problem\n",
    "        self.theta = np.linalg.inv(1/n @ X.T @ X + λ @ I) @ 1/n @ X.T @ y\n",
    "                \n",
    "    # predict the output from input (testing) data\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # append a column of ones at the beginning of X\n",
    "        X = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # return the outputs\n",
    "        return X @ self.theta\n",
    "    # return polynomial basis functions for degree M and d=1\n",
    "\n",
    "    def univariatePolynomialBasis(M):\n",
    "        def polynomialM(x):\n",
    "            # create an empty array\n",
    "            out = np.array([])\n",
    "            \n",
    "            # create the output\n",
    "            for i in range(M+1):\n",
    "                # append x^i\n",
    "                out = np.append(out, x ** i)\n",
    "            \n",
    "            # return the polynomial values\n",
    "            return out\n",
    "        print(polynomialM)\n",
    "\n",
    "        # return the polynomial function\n",
    "        return polynomialM\n",
    "\n",
    "    # return polynomial basis functions for d=1\n",
    "    def expBasis(M):\n",
    "        def exponential(x):\n",
    "            # create an empty array\n",
    "            out = np.array([])\n",
    "            \n",
    "            # create the output\n",
    "            for i in range(-M, M + 1):\n",
    "                # append x^i\n",
    "                out = np.append(out, np.exp(x*i/M))\n",
    "            \n",
    "            # return the polynomial values\n",
    "            return out\n",
    "        \n",
    "        # return the polynomial function\n",
    "        return exponential\n",
    "    \n",
    "    # return polynomial basis functions for degree M and d=1\n",
    "    def univariatePolynomialBasis(M):\n",
    "        def polynomialM(x):\n",
    "            # create an empty array\n",
    "            out = np.array([])\n",
    "            \n",
    "            # create the output\n",
    "            for i in range(M+1):\n",
    "                # append x^i\n",
    "                out = np.append(out, x ** i)\n",
    "            \n",
    "            # return the polynomial values\n",
    "            return out\n",
    "        print(polynomialM)\n",
    "\n",
    "        # return the polynomial function\n",
    "        return polynomialM\n",
    "\n",
    "    # return polynomial basis functions for d=1\n",
    "    def expBasis(M):\n",
    "        def exponential(x):\n",
    "            # create an empty array\n",
    "            out = np.array([])\n",
    "            \n",
    "            # create the output\n",
    "            for i in range(-M, M + 1):\n",
    "                # append x^i\n",
    "                out = np.append(out, np.exp(x*i/M))\n",
    "            \n",
    "            # return the polynomial values\n",
    "            return out\n",
    "        \n",
    "        # return the polynomial function\n",
    "        return exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the details about houses in a real estate dataset and attempt to predict the list price for the houses. Use the [Mount Pleasant Real Estate dataset](https://www.hawkeslearning.com/Statistics/dis/datasets.html).\n",
    "\n",
    "    a. **[5 points]** Read the dataset into Python and preprocess data excluding the \"Misc Exterior\" and \"Amenities\" columns into an appropriate data matrix for regression analysis. Randomly split the data into a training set, validation set, and test set at 60\\%/20\\%/20\\%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     List Price  Duplex?  Bedrooms  Baths - Total  Baths - Full  Baths - Half  \\\n",
      "0      369900.0      1.0       3.0            2.5           2.0           1.0   \n",
      "1      375000.0      1.0       3.0            2.5           2.0           1.0   \n",
      "2      769900.0      0.0       4.0            3.5           3.0           1.0   \n",
      "3      699990.0      0.0       4.0            3.5           3.0           1.0   \n",
      "4      436625.0      0.0       4.0            3.0           3.0           0.0   \n",
      "..          ...      ...       ...            ...           ...           ...   \n",
      "240   1800000.0      0.0       5.0            5.5           5.0           1.0   \n",
      "241   1495000.0      0.0       4.0            3.5           3.0           1.0   \n",
      "242   1399000.0      0.0       6.0            5.5           5.0           1.0   \n",
      "243   1250000.0      0.0       4.0            4.5           4.0           1.0   \n",
      "244   1100000.0      0.0       5.0            4.0           4.0           0.0   \n",
      "\n",
      "     Stories  Square Footage  Year Built  Acreage  ...  House Style_Colonial  \\\n",
      "0        2.0          1797.0      2017.0     0.06  ...                   0.0   \n",
      "1        2.0          1797.0      2017.0     0.06  ...                   0.0   \n",
      "2        2.0          2767.0      2014.0     0.35  ...                   0.0   \n",
      "3        2.0          3240.0      2014.0     0.29  ...                   0.0   \n",
      "4        2.0          2072.0      2017.0     0.19  ...                   0.0   \n",
      "..       ...             ...         ...      ...  ...                   ...   \n",
      "240      3.0          5401.0      2016.0     0.38  ...                   0.0   \n",
      "241      2.0          4100.0      2001.0     0.67  ...                   1.0   \n",
      "242      2.0          4400.0      2001.0     0.44  ...                   0.0   \n",
      "243      3.0          3621.0      2001.0     0.29  ...                   0.0   \n",
      "244      2.0          4030.0      2013.0     0.55  ...                   0.0   \n",
      "\n",
      "     House Style_Condo Regime  House Style_Condominium  \\\n",
      "0                         0.0                      0.0   \n",
      "1                         0.0                      0.0   \n",
      "2                         0.0                      0.0   \n",
      "3                         0.0                      0.0   \n",
      "4                         0.0                      0.0   \n",
      "..                        ...                      ...   \n",
      "240                       0.0                      0.0   \n",
      "241                       0.0                      0.0   \n",
      "242                       0.0                      0.0   \n",
      "243                       0.0                      0.0   \n",
      "244                       0.0                      0.0   \n",
      "\n",
      "     House Style_Contemporary  House Style_Cottage  House Style_Craftsman  \\\n",
      "0                         0.0                  0.0                    0.0   \n",
      "1                         0.0                  0.0                    0.0   \n",
      "2                         0.0                  0.0                    0.0   \n",
      "3                         0.0                  0.0                    0.0   \n",
      "4                         0.0                  0.0                    0.0   \n",
      "..                        ...                  ...                    ...   \n",
      "240                       0.0                  0.0                    0.0   \n",
      "241                       0.0                  0.0                    0.0   \n",
      "242                       0.0                  0.0                    0.0   \n",
      "243                       0.0                  0.0                    0.0   \n",
      "244                       0.0                  0.0                    0.0   \n",
      "\n",
      "     House Style_Patio  House Style_Ranch  House Style_Townhouse  \\\n",
      "0                  0.0                0.0                    1.0   \n",
      "1                  0.0                0.0                    1.0   \n",
      "2                  0.0                0.0                    0.0   \n",
      "3                  0.0                0.0                    0.0   \n",
      "4                  0.0                0.0                    0.0   \n",
      "..                 ...                ...                    ...   \n",
      "240                0.0                0.0                    0.0   \n",
      "241                0.0                0.0                    0.0   \n",
      "242                0.0                0.0                    0.0   \n",
      "243                0.0                0.0                    0.0   \n",
      "244                0.0                0.0                    0.0   \n",
      "\n",
      "     House Style_Traditional  \n",
      "0                        0.0  \n",
      "1                        0.0  \n",
      "2                        1.0  \n",
      "3                        1.0  \n",
      "4                        1.0  \n",
      "..                       ...  \n",
      "240                      1.0  \n",
      "241                      0.0  \n",
      "242                      1.0  \n",
      "243                      1.0  \n",
      "244                      1.0  \n",
      "\n",
      "[245 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "This cell is used to import the data from an excel file and store the data in a Pandas dataframe.\n",
    "Once data is in a pandas dataframe the data is cleaned to make all cells contain a numeric value\n",
    "rather than a string. Once all data prepation has been completed the data is split into train,\n",
    "test, and validate sets.\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path_to_file = \"/Users/spencerhirsch/Documents/GitHub/senior/mlwhite/hw/hw1/Mount_Pleasant_Real_Estate_Data.xlsx\"\n",
    "data = pd.read_excel(path_to_file)      # Take in file as excel file.\n",
    "\n",
    "'''\n",
    "The following code takes all values that contain the same string as identifiers and transforms them\n",
    "into boolean values by adding new columns to the table. In addition to this, all boolean values are\n",
    "represented as 1 for True and 0 for False. This was done to ensure that all values contained in the\n",
    "table were numeric values.\n",
    "'''\n",
    "\n",
    "data = pd.get_dummies(data, columns=[\"Subdivision\", \"House Style\"], drop_first=True)\n",
    "data = data.drop(columns=[\"Misc Exterior\", \"Amenities\", \"ID\"])\n",
    "data = data.dropna()\n",
    "data = data.replace({\"Yes\": 1, \"No\": 0})\n",
    "data = data.astype(float)\n",
    "print(data)\n",
    "\n",
    "\n",
    "dataY = data[\"List Price\"].to_numpy()                           # Dependent Variable saved as Y\n",
    "dataX = data.drop(columns = [\"List Price\"]).to_numpy()          # Determinants saved as X\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(dataX, dataY, test_size=0.4, random_state=0)\n",
    "valX, testX, valY, testY = train_test_split(testX, testY, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **[5 points]** Fit the least squares hyperplane to the training set to predict house prices, and evaluate its fit on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training set is 64936.83894059896\n",
      "\n",
      "The mean absolute error on the validation set is 79759.99252631378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# return the predicted outputs for the datapoints in the training set\n",
    "trainPredictions = model.predict(trainX)\n",
    "print('The mean absolute error on the training set is', mean_absolute_error(trainY, trainPredictions))\n",
    "print()\n",
    "predictions = model.predict(valX)\n",
    "print('The mean absolute error on the validation set is', mean_absolute_error(valY, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. **[5 points]** Fit a ridge regression to the training set to predict house prices, and evaluate its fit on the validation set. Repeat this for several different values of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error when λ = 0 on the validation set is 79771.39050740862\n",
      "The mean absolute error when λ = 0.1 on the validation set is 79544.22977663336\n",
      "The mean absolute error when λ = 1 on the validation set is 79023.32557467633\n",
      "The mean absolute error when λ = 2 on the validation set is 79581.54439277078\n",
      "The mean absolute error when λ = 5 on the validation set is 82066.62741450971\n",
      "The mean absolute error when λ = 10 on the validation set is 86147.87114315317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "lambdas = [0, 0.1, 1, 2, 5, 10]\n",
    "for λ in lambdas:\n",
    "    model = Ridge(alpha=λ)\n",
    "    model.fit(trainX, trainY)\n",
    "    prediction = model.predict(valX)\n",
    "    print('The mean absolute error when λ = %s on the validation set is %s' % (λ, str(mean_absolute_error(valY, prediction))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. **[5 points]** Fit an LBF expansion of your choice to the training set to predict house prices, and evaluate its fit on the validation set. Repeat this for several different values of $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error when λ = 0 on the validation set is 80016.41 with degree 1\n",
      "The mean absolute error when λ = 1e-06 on the validation set is 79760.40 with degree 1\n",
      "The mean absolute error when λ = 1e-05 on the validation set is 79760.36 with degree 1\n",
      "The mean absolute error when λ = 0.001 on the validation set is 79756.67 with degree 1\n",
      "The mean absolute error when λ = 0.1 on the validation set is 79544.23 with degree 1\n",
      "The mean absolute error when λ = 1 on the validation set is 79023.33 with degree 1\n",
      "The mean absolute error when λ = 0 on the validation set is 118701.51 with degree 2\n",
      "The mean absolute error when λ = 1e-06 on the validation set is 118701.51 with degree 2\n",
      "The mean absolute error when λ = 1e-05 on the validation set is 112589.89 with degree 2\n",
      "The mean absolute error when λ = 0.001 on the validation set is 108983.74 with degree 2\n",
      "The mean absolute error when λ = 0.1 on the validation set is 180012.73 with degree 2\n",
      "The mean absolute error when λ = 1 on the validation set is 111071.77 with degree 2\n",
      "The mean absolute error when λ = 0 on the validation set is 234603.65 with degree 3\n",
      "The mean absolute error when λ = 1e-06 on the validation set is 234603.65 with degree 3\n",
      "The mean absolute error when λ = 1e-05 on the validation set is 234603.65 with degree 3\n",
      "The mean absolute error when λ = 0.001 on the validation set is 234603.65 with degree 3\n",
      "The mean absolute error when λ = 0.1 on the validation set is 234603.65 with degree 3\n",
      "The mean absolute error when λ = 1 on the validation set is 234603.65 with degree 3\n",
      "The mean absolute error when λ = 0 on the validation set is 421547.76 with degree 4\n",
      "The mean absolute error when λ = 1e-06 on the validation set is 421547.76 with degree 4\n",
      "The mean absolute error when λ = 1e-05 on the validation set is 421547.76 with degree 4\n",
      "The mean absolute error when λ = 0.001 on the validation set is 421547.76 with degree 4\n",
      "The mean absolute error when λ = 0.1 on the validation set is 421547.76 with degree 4\n",
      "The mean absolute error when λ = 1 on the validation set is 421547.76 with degree 4\n",
      "The mean absolute error when λ = 0 on the validation set is 326584.58 with degree 5\n",
      "The mean absolute error when λ = 1e-06 on the validation set is 326584.58 with degree 5\n",
      "The mean absolute error when λ = 1e-05 on the validation set is 326584.58 with degree 5\n",
      "The mean absolute error when λ = 0.001 on the validation set is 326584.58 with degree 5\n",
      "The mean absolute error when λ = 0.1 on the validation set is 326584.58 with degree 5\n",
      "The mean absolute error when λ = 1 on the validation set is 326584.58 with degree 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "num_deg = [1, 2, 3, 4, 5]\n",
    "for m in num_deg:\n",
    "    poly = PolynomialFeatures(degree=m)\n",
    "\n",
    "    x_lbf_train = poly.fit_transform(trainX)\n",
    "    x_lbf_val = poly.fit_transform(valX)\n",
    "    lambdas = [0, 0.000001, 0.00001, 0.001, 0.1, 1]\n",
    "    for λ in lambdas:\n",
    "        lbf_model = Ridge(alpha=λ)\n",
    "        lbf_model.fit(x_lbf_train, trainY)\n",
    "        prediction = lbf_model.predict(x_lbf_val)\n",
    "        print('The mean absolute error when λ = %s on the validation set is %s with degree %s' % (λ, format(mean_absolute_error(valY, prediction), \".2f\"), m))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vehid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
